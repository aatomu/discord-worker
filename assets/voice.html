<!DOCTYPE html>
<html>

<head>
	<meta charset="utf-8">
	<title>SpeechToText</title>
	<style>
		body {
			padding: 0;
			margin: 0;
			width: 100vw;
			height: 100vh;

			display: flex;
			flex-direction: column;
			flex-wrap: nowrap;
			justify-content: center;
			align-items: center;

			background-color: #222831;
		}

		.log {
			width: 70vw;
			height: 15lh;

			border-radius: 1ch;
			border-width: 2px;
			border-style: solid;
			background-color: #31363F;
		}

		.mic_green {
			border-color: #B4E8C0
		}

		.mic_red {
			border-color: #EE9494
		}

		.log>span:not(.temporary) {
			color: #76ABAE;
		}

		.interface {
			margin: 1ch;
			padding: 1ch;
			width: 30vw;

			border-radius: 1ch;
			background-color: #EEEEEE;
		}

		.temporary {
			color: gray;
		}
	</style>
</head>

<body>
	<div id="log" class="log">
		<span id="temporary" class="temporary">...</span>
	</div>
	<div class="interface">
		<button id="enable">Enable</button><br>
		<span id="stat">Status:</span><br>
	</div>
</body>

<script>
	const url = new URL(window.location.href)
	const param = new URLSearchParams(url.searchParams)
	let autoRestart = true

	// WebAudioAPI Call
	const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
	const recognition = new SpeechRecognition();
	recognition.continuous = true;
	recognition.interimResults = true
	recognition.lang = "ja-jp";

	// Event:
	// start soundstart speechstart speechend soundend end
	recognition.addEventListener("speechstart", () => {
		console.log("speechstart")

		const log = document.getElementById("log")
		log.classList.add("mic_green")
		log.classList.remove("mic_red")
	})
	recognition.addEventListener("speechend", () => {
		console.log("speechend")

		if (autoRestart) {
			recognition.stop()

			setTimeout(() => {
				recognition.start()
			}, 5 * 1000)
		}
	})

	recognition.addEventListener("error", (e) => {
		console.log("error", e)
		setStat(`Error "${e.error}"`)
		autoRestart = false

		const log = document.getElementById("log")
		log.classList.add("mic_red")
		log.classList.remove("mic_green")
	})

	recognition.addEventListener("result", (event) => {
		const temporary = document.getElementById("temporary")
		const log = document.getElementById("log")
		const index = event.results.length - 1
		const text = event.results[index][0].transcript

		if (event.results[index].isFinal) {
			if (text == "") {
				return
			}
			const now = new Date()
			console.log("解析完了:", text)
			const logLine = document.createElement("span")
			logLine.innerText = `${now.getHours().toString().padStart(2, "0")}:${now.getMinutes().toString().padStart(2, "0")}:${now.getSeconds().toString().padStart(2, "0")}.${now.getMilliseconds().toString().substring(0, 3).padEnd(3, "0")} ${text}`
			log.insertBefore(logLine, temporary)
			log.insertBefore(document.createElement("br"), temporary)
			temporary.innerText = "..."

			const id = param.get("id")
			const token = param.get("token")
			if (id && token) {
				fetch(`/voice_save`, {
					method: "POST",
					headers: {
						"Content-Type": "application/json"
					},
					body: JSON.stringify({
						id: id,
						token: token,
						text: text
					})
				})
			}

			return
		}

		console.log("認識途中:", text)
		temporary.innerText = text
	})

	document.getElementById("enable").addEventListener("click", async () => {
		setStat("Wait permission accept")
		await recognition.start()
		setStat("Speech to text Ready...")
	})

	function setStat(message) {
		const stat = document.getElementById("stat")
		stat.innerText = `Stat: ${message}`
	}
</script>

</html>
